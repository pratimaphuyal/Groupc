{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_modeling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY0SJUCSY305"
      },
      "source": [
        "#### Copyright 2018 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q1hsKyBZDVu"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5tftaRtUcm7"
      },
      "source": [
        "#Intro to Modeling\n",
        "\n",
        "\n",
        "**Learning Objectives:**\n",
        "* Become familiar with pandas for handling small datasets\n",
        "* Use the tf.Estimator and Feature Column API to experiment with feature transformations\n",
        "* Use visualizations and run experiments to understand the value of feature transformations\n",
        "\n",
        "Please **make a copy** of this Colab notebook before starting this lab. To do so, choose **File**->**Save a copy in Drive**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT_bZ9E0ZWaN"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Let's start by importing our dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "wZ_T2SgDVKUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6abf7c-2806-4ae3-bee6-77289171c2d0"
      },
      "source": [
        "%reset -f\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "!pip install tensorflow==2.15\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.15 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.0.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.2.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx4-PWE-VaD_"
      },
      "source": [
        "## Pandas, a helpful data analysis library for in-memory dataset\n",
        "\n",
        "We use a package called [Pandas](http://pandas.pydata.org/) for reading in our data, exploring our data and doing some basic processing. It is really helpful for datasets that fit in memory! And it has some nice integrations, as you will see.\n",
        "\n",
        "First we set up some options to control how items are displayed and the maximum number of rows to show when displaying a table.  Feel free to change this setup to whatever you'd like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKUIMcPCVRqv"
      },
      "source": [
        "# Set pandas output display to have one digit for decimal places and limit it to\n",
        "# printing 15 rows.\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "pd.options.display.max_rows = 15"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_fTMztUVelY"
      },
      "source": [
        "### Load the dataset with pandas\n",
        "The car data set we will be using in this lab is provided as a comma separated file without a header row.  In order for each column to have a meaningful header name we must provide it.  We get the information about the columns from the [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/automobile).\n",
        "\n",
        "We will use the features of the car, to try to predict its price.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "Y38V73EgVYwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "899d80dd-b696-4bcd-c117-d855a2c95d87"
      },
      "source": [
        "# Provide the names for the columns since the CSV file with the data does\n",
        "# not have a header row.\n",
        "feature_names = ['symboling', 'normalized-losses', 'make', 'fuel-type',\n",
        "        'aspiration', 'num-doors', 'body-style', 'drive-wheels',\n",
        "        'engine-location', 'wheel-base', 'length', 'width', 'height', 'weight',\n",
        "        'engine-type', 'num-cylinders', 'engine-size', 'fuel-system', 'bore',\n",
        "        'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg',\n",
        "        'highway-mpg', 'price']\n",
        "\n",
        "\n",
        "# Load in the data from a CSV file that is comma separated.\n",
        "car_data = pd.read_csv('https://storage.googleapis.com/mledu-datasets/cars_data.csv',\n",
        "                        sep=',', names=feature_names, header=None, encoding='latin-1')\n",
        "\n",
        "\n",
        "# We'll then randomize the data, just to be sure not to get any pathological\n",
        "# ordering effects that might harm the performance of Stochastic Gradient\n",
        "# Descent.\n",
        "car_data = car_data.reindex(np.random.permutation(car_data.index))\n",
        "\n",
        "print(\"Data set loaded. Num examples: \", len(car_data))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data set loaded. Num examples:  205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAHZBtDlkmGa"
      },
      "source": [
        "This is a really small dataset! Only 205 examples.\n",
        "\n",
        "For simplicity in this codelab, we do not split the data further into training and validation. But you MUST do this on real datasets, or else you will overfit to your single dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ1HxLrOVqZk"
      },
      "source": [
        "## Task 0: Use pandas to explore and prepare the data\n",
        "\n",
        "- Use Pandas to inspect the data and manually curate a list of numeric_feature_names and categorical_feature_names.\n",
        "\n",
        "\n",
        "Useful functions:\n",
        "- `type()` called on any Python object describes the type of the object\n",
        "- `dataframe[4:7]` pulls out rows 4, 5, 6 in a Pandas dataframe\n",
        "- `dataframe[['mycol1', 'mycol2']]` pulls out the two requested columns into a new Pandas dataframe\n",
        "- `dataframe['mycol1']` returns a Pandas series -- not a dataframe!\n",
        "- `dataframe.describe()` prints out statistics for each dataframe column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfeHYeMf7PwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "82c82ace-213c-4377-a97d-8b8b4f382566"
      },
      "source": [
        "car_data[4:7]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     symboling normalized-losses           make fuel-type aspiration  \\\n",
              "18           2               121      chevrolet       gas        std   \n",
              "70          -1                93  mercedes-benz    diesel      turbo   \n",
              "144          0               102         subaru       gas        std   \n",
              "\n",
              "    num-doors body-style drive-wheels engine-location  wheel-base  ...  \\\n",
              "18        two  hatchback          fwd           front       88.40  ...   \n",
              "70       four      sedan          rwd           front      115.60  ...   \n",
              "144      four      sedan          4wd           front       97.00  ...   \n",
              "\n",
              "     engine-size  fuel-system  bore  stroke compression-ratio horsepower  \\\n",
              "18            61         2bbl  2.91    3.03              9.50         48   \n",
              "70           183          idi  3.58    3.64             21.50        123   \n",
              "144          108         2bbl  3.62    2.64              9.00         82   \n",
              "\n",
              "     peak-rpm city-mpg highway-mpg  price  \n",
              "18       5100       47          53   5151  \n",
              "70       4350       22          25  31600  \n",
              "144      4800       24          25   9233  \n",
              "\n",
              "[3 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f68176de-4450-4747-a583-34b33c3ac77e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symboling</th>\n",
              "      <th>normalized-losses</th>\n",
              "      <th>make</th>\n",
              "      <th>fuel-type</th>\n",
              "      <th>aspiration</th>\n",
              "      <th>num-doors</th>\n",
              "      <th>body-style</th>\n",
              "      <th>drive-wheels</th>\n",
              "      <th>engine-location</th>\n",
              "      <th>wheel-base</th>\n",
              "      <th>...</th>\n",
              "      <th>engine-size</th>\n",
              "      <th>fuel-system</th>\n",
              "      <th>bore</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compression-ratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peak-rpm</th>\n",
              "      <th>city-mpg</th>\n",
              "      <th>highway-mpg</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2</td>\n",
              "      <td>121</td>\n",
              "      <td>chevrolet</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>hatchback</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>88.40</td>\n",
              "      <td>...</td>\n",
              "      <td>61</td>\n",
              "      <td>2bbl</td>\n",
              "      <td>2.91</td>\n",
              "      <td>3.03</td>\n",
              "      <td>9.50</td>\n",
              "      <td>48</td>\n",
              "      <td>5100</td>\n",
              "      <td>47</td>\n",
              "      <td>53</td>\n",
              "      <td>5151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>-1</td>\n",
              "      <td>93</td>\n",
              "      <td>mercedes-benz</td>\n",
              "      <td>diesel</td>\n",
              "      <td>turbo</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>115.60</td>\n",
              "      <td>...</td>\n",
              "      <td>183</td>\n",
              "      <td>idi</td>\n",
              "      <td>3.58</td>\n",
              "      <td>3.64</td>\n",
              "      <td>21.50</td>\n",
              "      <td>123</td>\n",
              "      <td>4350</td>\n",
              "      <td>22</td>\n",
              "      <td>25</td>\n",
              "      <td>31600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "      <td>subaru</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>4wd</td>\n",
              "      <td>front</td>\n",
              "      <td>97.00</td>\n",
              "      <td>...</td>\n",
              "      <td>108</td>\n",
              "      <td>2bbl</td>\n",
              "      <td>3.62</td>\n",
              "      <td>2.64</td>\n",
              "      <td>9.00</td>\n",
              "      <td>82</td>\n",
              "      <td>4800</td>\n",
              "      <td>24</td>\n",
              "      <td>25</td>\n",
              "      <td>9233</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f68176de-4450-4747-a583-34b33c3ac77e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f68176de-4450-4747-a583-34b33c3ac77e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f68176de-4450-4747-a583-34b33c3ac77e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f6f8449c-99ba-4a87-8119-066b0511e1c4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6f8449c-99ba-4a87-8119-066b0511e1c4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f6f8449c-99ba-4a87-8119-066b0511e1c4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "VsOUrVozoe9u"
      },
      "source": [
        "LABEL = 'price'\n",
        "\n",
        "numeric_feature_names = car_data[['symboling','normalized-losses','wheel-base','engine-size','bore','stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg','price']]\n",
        "categorical_feature_names = list(set(feature_names) - set(numeric_feature_names) - set([LABEL]))\n",
        "\n",
        "# The correct solution will pass these assert statements.\n",
        "assert len(numeric_feature_names) == 15\n",
        "assert len(categorical_feature_names) == 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "lLFkHgBm8O1Y"
      },
      "source": [
        "#@title Solution (to view code, from cell's menu, select Form -> Show Code)\n",
        "numeric_feature_names = ['symboling', 'normalized-losses', 'wheel-base',\n",
        "        'length', 'width', 'height', 'weight', 'engine-size', 'horsepower',\n",
        "        'peak-rpm', 'city-mpg', 'highway-mpg', 'bore', 'stroke',\n",
        "         'compression-ratio']\n",
        "\n",
        "categorical_feature_names = list(set(feature_names) - set(numeric_feature_names) - set([LABEL]))\n",
        "\n",
        "assert len(numeric_feature_names) == 15\n",
        "assert len(categorical_feature_names) == 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nabeQFGBpDEN"
      },
      "source": [
        "# Run to inspect numeric features.\n",
        "car_data[numeric_feature_names]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1ss9Q7mpiBy"
      },
      "source": [
        "# Run to inspect categorical features.\n",
        "car_data[categorical_feature_names]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OjDegBgqNnu"
      },
      "source": [
        "# Coerce the numeric features to numbers. This is necessary because the model\n",
        "# crashes because not all the values are numeric.\n",
        "for feature_name in numeric_feature_names + [LABEL]:\n",
        "  car_data[feature_name] = pd.to_numeric(car_data[feature_name], errors='coerce')\n",
        "\n",
        "# Fill missing values with 0.\n",
        "# Is this an OK thing to do? You may want to come back and revisit this decision later.\n",
        "car_data.fillna(0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq-t-8GPvnCW"
      },
      "source": [
        "## Task 1: Make your best model with numeric features. No normalization allowed.\n",
        "\n",
        "Modify the model provided below to achieve the lowest eval loss. You may want to change various hyperparameters:\n",
        "- learning rate\n",
        "- choice of optimizer\n",
        "- hidden layer dimensions -- make sure your choice here makes sense given the number of training examples\n",
        "- batch size\n",
        "- num training steps\n",
        "- (anything else you can think of changing)\n",
        "\n",
        "Do not use the `normalizer_fn` arg on `numeric_column`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH6KJp-4-E_Q"
      },
      "source": [
        "# This code \"works\", but because of bad hyperparameter choices it gets NaN loss\n",
        "# during training. Try fixing this.\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "print(numeric_feature_names)\n",
        "x_df = car_data[numeric_feature_names]\n",
        "y_series = car_data['price']\n",
        "\n",
        "# Create input_fn's so that the estimator knows how to read in your data.\n",
        "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "\n",
        "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "# Feature columns allow the model to parse the data, perform common\n",
        "# preprocessing, and automatically generate an input layer for the tf.Estimator.\n",
        "model_feature_columns = [\n",
        "    tf.feature_column.numeric_column(feature_name) for feature_name in numeric_feature_names\n",
        "]\n",
        "print('model_feature_columns', model_feature_columns)\n",
        "\n",
        "est = tf.estimator.DNNRegressor(\n",
        "    feature_columns=model_feature_columns,\n",
        "    hidden_units=[64],\n",
        "    optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01),\n",
        "  )\n",
        "\n",
        "# TRAIN\n",
        "num_print_statements = 10\n",
        "num_training_steps = 10000\n",
        "for _ in range(num_print_statements):\n",
        "  est.train(train_input_fn, steps=num_training_steps // num_print_statements)\n",
        "  scores = est.evaluate(eval_input_fn)\n",
        "\n",
        "  # The `scores` dictionary has several metrics automatically generated by the\n",
        "  # canned Estimator.\n",
        "  # `average_loss` is the average loss for an individual example.\n",
        "  # `loss` is the summed loss for the batch.\n",
        "  # In addition to these scalar losses, you may find the visualization functions\n",
        "  # in the next cell helpful for debugging model quality.\n",
        "  print('scores', scores)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "3ptcfj_9Xi9M"
      },
      "source": [
        "#@title Possible solution\n",
        "# Here is one possible solution:\n",
        "# The only necessary change to fix the NaN training loss was the choice of optimizer.\n",
        "\n",
        "# Changing other parameters could improve model quality, but take it with a\n",
        "# grain of salt. The dataset is very small.\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "print(numeric_feature_names)\n",
        "x_df = car_data[numeric_feature_names]\n",
        "y_series = car_data['price']\n",
        "\n",
        "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "\n",
        "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "# Feature columns allow the model to parse the data, perform common\n",
        "# preprocessing, and automatically generate an input layer for the tf.Estimator.\n",
        "model_feature_columns = [\n",
        "    tf.feature_column.numeric_column(feature_name) for feature_name in numeric_feature_names\n",
        "]\n",
        "print('model_feature_columns', model_feature_columns)\n",
        "\n",
        "est = tf.estimator.DNNRegressor(\n",
        "    feature_columns=model_feature_columns,\n",
        "    hidden_units=[64],\n",
        "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.01),\n",
        "  )\n",
        "\n",
        "# TRAIN\n",
        "num_print_statements = 10\n",
        "num_training_steps = 10000\n",
        "for _ in range(num_print_statements):\n",
        "  est.train(train_input_fn, steps=num_training_steps // num_print_statements)\n",
        "  scores = est.evaluate(eval_input_fn)\n",
        "\n",
        "  # The `scores` dictionary has several metrics automatically generated by the\n",
        "  # canned Estimator.\n",
        "  # `average_loss` is the average loss for an individual example.\n",
        "  # `loss` is the summed loss for the batch.\n",
        "  # In addition to these scalar losses, you may find the visualization functions\n",
        "  # in the next cell helpful for debugging model quality.\n",
        "  print('scores', scores)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxto3DwsjYw4"
      },
      "source": [
        "### Visualize your model's predictions\n",
        "\n",
        "After you have a trained model, it may be helpful to understand how your model's inference differs from the actual data.\n",
        "\n",
        "This helper function `scatter_plot_inference` does that for you. Real data is in grey. Your model's predictions are in orange.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGSXwX2fju1N"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def scatter_plot_inference_grid(est, x_df, feature_names):\n",
        "  \"\"\"Plots the predictions of the model against each feature.\n",
        "\n",
        "  Args:\n",
        "    est: The trained tf.Estimator.\n",
        "    x_df: The pandas dataframe with the input data (used to create\n",
        "      predict_input_fn).\n",
        "    feature_names: An iterable of string feature names to plot.\n",
        "  \"\"\"\n",
        "  def scatter_plot_inference(axis,\n",
        "                             x_axis_feature_name,\n",
        "                             y_axis_feature_name,\n",
        "                             predictions):\n",
        "    \"\"\"Generate one subplot.\"\"\"\n",
        "    # Plot the real data in grey.\n",
        "    y_axis_feature_name = 'price'\n",
        "    axis.set_ylabel(y_axis_feature_name)\n",
        "    axis.set_xlabel(x_axis_feature_name)\n",
        "    axis.scatter(car_data[x_axis_feature_name],\n",
        "                 car_data[y_axis_feature_name],\n",
        "                 c='grey')\n",
        "\n",
        "    # Plot the predicted data in orange.\n",
        "    axis.scatter(car_data[x_axis_feature_name], predictions, c='orange')\n",
        "\n",
        "  predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "  predictions = [\n",
        "    x['predictions'][0]\n",
        "    for x in est.predict(predict_input_fn)\n",
        "  ]\n",
        "\n",
        "  num_cols = 3\n",
        "  num_rows = int(math.ceil(len(feature_names)/float(num_cols)))\n",
        "  f, axarr = plt.subplots(num_rows, num_cols)\n",
        "  size = 4.5\n",
        "  f.set_size_inches(num_cols*size, num_rows*size)\n",
        "\n",
        "  for i, feature_name in enumerate(numeric_feature_names):\n",
        "    axis = axarr[int(i/num_cols), i%num_cols]\n",
        "    scatter_plot_inference(axis, feature_name, 'price', predictions)\n",
        "  plt.show()\n",
        "\n",
        "scatter_plot_inference_grid(est, x_df, numeric_feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBZI8f_8Yfph"
      },
      "source": [
        "## Task 2: Take your best numeric model from earlier. Add normalization.\n",
        "\n",
        "### Add normalization to your best numeric model from earlier\n",
        "\n",
        "- You decide what type of normalization to add, and for which features\n",
        "- You will need to use the `normalizer_fn` arg on [`numeric_column`](https://g3doc.corp.google.com/learning/brain/public/g3doc/api_docs/python/tf/feature_column/numeric_column.md?cl=head)\n",
        "    - An example of a silly normalizer_fn that shifts inputs down by 1, and then negates the value:\n",
        "    \n",
        "         normalizer_fn = lambda x: tf.neg(tf.subtract(x, 1))\n",
        "\n",
        "- You may find these pandas functions helpful:\n",
        "    - dataframe.mean()['your_feature_name']\n",
        "    - dataframe.std()['your_feature_name']\n",
        "- You will need to retune the hyperparameters from earlier.\n",
        "\n",
        "\n",
        "**Does normalization improve model quality on this dataset? Why or why not?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY_C_QgcZg1-"
      },
      "source": [
        "# This 1D visualization of each numeric feature might inform your normalization\n",
        "# decisions.\n",
        "for feature_name in numeric_feature_names:\n",
        "  car_data.hist(column=feature_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiEpDZKSj8pN"
      },
      "source": [
        "###Train your model with numeric features + normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c30Y6IiR8iVn"
      },
      "source": [
        "## Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxYJy71zaZsy"
      },
      "source": [
        "#@title Possible solution\n",
        "# This does Z-score normalization since the distributions for most features looked\n",
        "# roughly normally distributed.\n",
        "\n",
        "# Z-score normalization subtracts the mean and divides by the standard deviation,\n",
        "# to give a roughly standard normal distribution (mean = 0, std = 1) under a\n",
        "# normal distribution assumption. Epsilon prevents divide by zero.\n",
        "\n",
        "# With normalization, are you able to get the model working with\n",
        "# GradientDescentOptimizer? Z-score normalization doesn't seem to be able to get\n",
        "# SGD working. Maybe a different type of normalization would?\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "print(numeric_feature_names)\n",
        "x_df = car_data[numeric_feature_names]\n",
        "y_series = car_data['price']\n",
        "\n",
        "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "\n",
        "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "# Epsilon prevents divide by zero.\n",
        "epsilon = 0.000001\n",
        "model_feature_columns = [\n",
        "    tf.feature_column.numeric_column(feature_name,\n",
        "                                     normalizer_fn=lambda val: (val - x_df.mean()[feature_name]) / (epsilon + x_df.std()[feature_name]))\n",
        "    for feature_name in numeric_feature_names\n",
        "]\n",
        "print('model_feature_columns', model_feature_columns)\n",
        "\n",
        "est = tf.estimator.DNNRegressor(\n",
        "    feature_columns=model_feature_columns,\n",
        "    hidden_units=[64],\n",
        "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.01),\n",
        "  )\n",
        "\n",
        "# TRAIN\n",
        "num_print_statements = 10\n",
        "num_training_steps = 10000\n",
        "for _ in range(num_print_statements):\n",
        "  est.train(train_input_fn, steps=num_training_steps // num_print_statements)\n",
        "  scores = est.evaluate(eval_input_fn)\n",
        "\n",
        "  # The `scores` dictionary has several metrics automatically generated by the\n",
        "  # canned Estimator.\n",
        "  # `average_loss` is the average loss for an individual example.\n",
        "  # `loss` is the summed loss for the batch.\n",
        "  # In addition to these scalar losses, you may find the visualization functions\n",
        "  # in the next cell helpful for debugging model quality.\n",
        "  print('scores', scores)\n",
        "\n",
        "scatter_plot_inference_grid(est, x_df, numeric_feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fruh0Qj5_Bos"
      },
      "source": [
        "## Task 3: Make your best model using only categorical features\n",
        "\n",
        "- Look at the possible feature columns for categorical features. They begin with `categorical_column_with_` in go/tf-ops.\n",
        "- You may find `dataframe[categorical_feature_names].unique()` helpful.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "-udhHnNS2WvN"
      },
      "source": [
        "## Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EftIzPAI9RJj"
      },
      "source": [
        "#@title Possible solution\n",
        "# We have the full list of values that each feature takes on, and the list is\n",
        "# relatively small so we use categorical_column_with_vocabulary_list.\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "x_df = car_data[categorical_feature_names]\n",
        "y_series = car_data['price']\n",
        "\n",
        "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "\n",
        "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "model_feature_columns = [\n",
        "    tf.feature_column.indicator_column(\n",
        "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            feature_name, vocabulary_list=car_data[feature_name].unique()))\n",
        "    for feature_name in categorical_feature_names\n",
        "]\n",
        "print('model_feature_columns', model_feature_columns)\n",
        "\n",
        "est = tf.estimator.DNNRegressor(\n",
        "    feature_columns=model_feature_columns,\n",
        "    hidden_units=[64],\n",
        "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.01),\n",
        "  )\n",
        "\n",
        "# TRAIN\n",
        "num_print_statements = 10\n",
        "num_training_steps = 10000\n",
        "for _ in range(num_print_statements):\n",
        "  est.train(train_input_fn, steps=num_training_steps // num_print_statements)\n",
        "  scores = est.evaluate(eval_input_fn)\n",
        "\n",
        "  # The `scores` dictionary has several metrics automatically generated by the\n",
        "  # canned Estimator.\n",
        "  # `average_loss` is the average loss for an individual example.\n",
        "  # `loss` is the summed loss for the batch.\n",
        "  # In addition to these scalar losses, you may find the visualization functions\n",
        "  # in the next cell helpful for debugging model quality.\n",
        "  print('scores', scores)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyBH5Wai_HTD"
      },
      "source": [
        "## Task 4: Using all the features, make the best model that you can make\n",
        "\n",
        "With all the features combined, your model should perform better than your earlier models using numerical and categorical models alone. Tune your model until that is the case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNfCzC-q8edv"
      },
      "source": [
        "## Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmaGHWFVGKMr"
      },
      "source": [
        "#@title Possible solution\n",
        "# This is a first pass at a model that uses all the features.\n",
        "# Do you have any improvements?\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "x_df = car_data[numeric_feature_names + categorical_feature_names]\n",
        "y_series = car_data['price']\n",
        "\n",
        "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "\n",
        "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "epsilon = 0.000001\n",
        "model_feature_columns = [\n",
        "    tf.feature_column.indicator_column(\n",
        "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            feature_name, vocabulary_list=car_data[feature_name].unique()))\n",
        "    for feature_name in categorical_feature_names\n",
        "] + [\n",
        "    tf.feature_column.numeric_column(feature_name,\n",
        "                                     normalizer_fn=lambda val: (val - x_df.mean()[feature_name]) / (epsilon + x_df.std()[feature_name]))\n",
        "    for feature_name in numeric_feature_names\n",
        "]\n",
        "\n",
        "\n",
        "print('model_feature_columns', model_feature_columns)\n",
        "\n",
        "est = tf.estimator.DNNRegressor(\n",
        "    feature_columns=model_feature_columns,\n",
        "    hidden_units=[64],\n",
        "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.01),\n",
        "  )\n",
        "\n",
        "# TRAIN\n",
        "num_print_statements = 10\n",
        "num_training_steps = 10000\n",
        "for _ in range(num_print_statements):\n",
        "  est.train(train_input_fn, steps=num_training_steps // num_print_statements)\n",
        "  scores = est.evaluate(eval_input_fn)\n",
        "\n",
        "  # The `scores` dictionary has several metrics automatically generated by the\n",
        "  # canned Estimator.\n",
        "  # `average_loss` is the average loss for an individual example.\n",
        "  # `loss` is the summed loss for the batch.\n",
        "  # In addition to these scalar losses, you may find the visualization functions\n",
        "  # in the next cell helpful for debugging model quality.\n",
        "  print('scores', scores)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}